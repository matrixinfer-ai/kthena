# This example shows how to deploy a DS1.5B model server.
# The DS1.5B server will provide inference services for the DS1.5B model.
#
# NOTE: Update the image to the correct DS1.5B model image once it's available.

apiVersion: apps/v1
kind: Deployment
metadata:
  name: deepseek-r1-1-5b-v1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: deepseek-r1-1-5b
      version: v1
  template:
    metadata:
      labels:
        app: deepseek-r1-1-5b
        version: v1
    spec:
      containers:
        - name: llm-engine
          image: ghcr.io/yaozengzeng/vllm-mock:latest
          imagePullPolicy: IfNotPresent
          env:
            # specify the model name to mock
            - name: MODEL_NAME
              value: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-v1"
          command:
            - python3
            - app.py
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deepseek-r1-1-5b-v2
spec:
  replicas: 1
  selector:
    matchLabels:
      app: deepseek-r1-1-5b
      version: v2
  template:
    metadata:
      labels:
        app: deepseek-r1-1-5b
        version: v2
    spec:
      containers:
        - name: llm-engine
          image: ghcr.io/yaozengzeng/vllm-mock:latest
          imagePullPolicy: IfNotPresent
          env:
            # specify the model name to mock
            - name: MODEL_NAME
              value: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-v2"
          command:
            - python3
            - app.py
