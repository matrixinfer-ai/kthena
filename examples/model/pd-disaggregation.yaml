apiVersion: registry.matrixinfer.ai/v1
kind: Model
metadata:
  name: ds-v3-671b-pd
  namespace: demo
spec:
  name: ds-pd-test
  owner: example
  backends:
    - cacheURI: hostpath:///tmp/cache/
      env:
        - name: HF_ENDPOINT
          value: https://hf-mirror.com/
      maxReplicas: 1
      minReplicas: 1
      modelURI: hf://deepseek-ai/DeepSeek-V2-Lite
      name: ds-pd-test
      routeWeight: 100
      type: vLLMDisaggregated
      workers:
        - config:
            enforce-eager: ""
            gpu-memory-utilization: 0.8
            kv-transfer-config: |
              {"kv_connector": "MooncakeConnectorV1",
                "kv_buffer_device": "npu",
                "kv_role": "kv_producer",
                "kv_parallel_size": 1,
                "kv_port": "20001",
                "engine_id": "0",
                "kv_rank": 0,
                "kv_connector_module_path": "vllm_ascend.distributed.mooncake_connector",
                "kv_connector_extra_config": {
                  "prefill": {
                    "dp_size": 2,
                    "tp_size": 2
                  },
                  "decode": {
                    "dp_size": 2,
                    "tp_size": 2
                  }
                }
              }
            max-model-len: 2000
            max-num-batched-tokens: 2000
            served-model-name: deepseek-ai/DeepSeekV2
            tensor-parallel-size: 2
            trust-remote-code: ""
          image: vllm-ascend_v0.10.1rc1_mooncake_v0.3.5 # todo: we need build this
          pods: 1
          replicas: 1
          resources:
            limits:
              cpu: "8"
              huawei.com/ascend-1980: "4"
              memory: 64Gi
            requests:
              cpu: "8"
              huawei.com/ascend-1980: "4"
              memory: 64Gi
          type: prefill
        - config:
            enforce-eager: ""
            gpu-memory-utilization: 0.8
            kv-transfer-config: |
              {"kv_connector": "MooncakeConnectorV1",
                "kv_buffer_device": "npu",
                "kv_role": "kv_consumer",
                "kv_parallel_size": 1,
                "kv_port": "20002",
                "engine_id": "1",
                "kv_rank": 1,
                "kv_connector_module_path": "vllm_ascend.distributed.mooncake_connector",
                "kv_connector_extra_config": {
                  "prefill": {
                    "dp_size": 2,
                    "tp_size": 2
                  },
                  "decode": {
                    "dp_size": 2,
                    "tp_size": 2
                  }
                }
              }
            max-model-len: 2000
            max-num-batched-tokens: 2000
            served-model-name: deepseek-ai/DeepSeekV2
            tensor-parallel-size: 2
            trust-remote-code: ""
          image: vllm-ascend_v0.10.1rc1_mooncake_v0.3.5 # todo: we need build this
          pods: 1
          replicas: 1
          resources:
            limits:
              cpu: "8"
              huawei.com/ascend-1980: "4"
              memory: 64Gi
            requests:
              cpu: "8"
              huawei.com/ascend-1980: "4"
              memory: 64Gi
          type: decode