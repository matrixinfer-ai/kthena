---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.17.2
  name: modelservers.networking.matrixinfer.ai
spec:
  group: networking.matrixinfer.ai
  names:
    kind: ModelServer
    listKind: ModelServerList
    plural: modelservers
    singular: modelserver
  scope: Namespaced
  versions:
  - name: v1alpha1
    schema:
      openAPIV3Schema:
        description: ModelServer is the Schema for the modelservers API.
        properties:
          apiVersion:
            description: |-
              APIVersion defines the versioned schema of this representation of an object.
              Servers should convert recognized schemas to the latest internal value, and
              may reject unrecognized values.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
            type: string
          kind:
            description: |-
              Kind is a string value representing the REST resource this object represents.
              Servers may infer this from the endpoint the client submits requests to.
              Cannot be updated.
              In CamelCase.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
            type: string
          metadata:
            type: object
          spec:
            description: ModelServerSpec defines the desired state of ModelServer.
            properties:
              inferenceEngine:
                description: The inference framework used to manage the model.
                enum:
                - vLLM
                - sgLang
                type: string
              model:
                description: |-
                  The real model that the modelServers are running.
                  If the `model` in LLM inference request is different from this field, it should be overwritten by this field.
                  Otherwise, the `model` in LLM inference request will not be mutated.
                maxLength: 256
                type: string
              port:
                description: The port of the model server.
                properties:
                  number:
                    description: A valid non-negative integer port number.
                    format: int32
                    type: integer
                    x-kubernetes-validations:
                    - message: port must be between 1-65535
                      rule: 0 < self && self <= 65535
                  protocol:
                    default: HTTP
                    description: |-
                      The protocol of the model server.
                      MUST be one of HTTP|HTTPS
                    enum:
                    - HTTP
                    - HTTPS
                    type: string
                required:
                - number
                - protocol
                type: object
              trafficPolicy:
                description: Traffic Policy for accessing the model server instance.
                properties:
                  retry:
                    description: The retry policy for the inference request.
                    properties:
                      attempts:
                        description: |-
                          The maximum number of times an individual inference request to a model server should be retried.
                          If the maximum number of retries is exceeded without a successgful response, the request will be considered failed.
                        format: int32
                        type: integer
                      retryInterval:
                        default: 100ms
                        description: RetryInterval is the interval between retries.
                        type: string
                    type: object
                  timeout:
                    description: |-
                      The request timeout for the inference request.
                      By default, there is no timeout.
                    type: string
                type: object
              workloadSelector:
                description: |-
                  WorkloadSelector is used to match the model servring instances.
                  Currently they must be pods within the same namespace as modelServer object.
                properties:
                  matchLabels:
                    additionalProperties:
                      type: string
                    type: object
                type: object
            required:
            - inferenceEngine
            - port
            - workloadSelector
            type: object
          status:
            description: ModelServerStatus defines the observed state of ModelServer.
            type: object
        type: object
    served: true
    storage: true
    subresources:
      status: {}
