---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.17.2
  name: modelservers.networking.matrixinfer.ai
spec:
  group: networking.matrixinfer.ai
  names:
    kind: ModelServer
    listKind: ModelServerList
    plural: modelservers
    singular: modelserver
  scope: Namespaced
  versions:
  - name: v1alpha1
    schema:
      openAPIV3Schema:
        description: ModelServer is the Schema for the modelservers API.
        properties:
          apiVersion:
            description: |-
              APIVersion defines the versioned schema of this representation of an object.
              Servers should convert recognized schemas to the latest internal value, and
              may reject unrecognized values.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
            type: string
          kind:
            description: |-
              Kind is a string value representing the REST resource this object represents.
              Servers may infer this from the endpoint the client submits requests to.
              Cannot be updated.
              In CamelCase.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
            type: string
          metadata:
            type: object
          spec:
            description: ModelServerSpec defines the desired state of ModelServer.
            properties:
              inferenceEngine:
                description: The inference engine used to serve the model.
                enum:
                - vLLM
                - SGLang
                type: string
              model:
                description: |-
                  The real model that the modelServers are running.
                  If the `model` in LLM inference request is different from this field, it should be overwritten by this field.
                  Otherwise, the `model` in LLM inference request will not be mutated.
                maxLength: 256
                type: string
              trafficPolicy:
                description: Traffic Policy for accessing the model server instance.
                properties:
                  retry:
                    description: The retry policy for the inference request.
                    properties:
                      attempts:
                        description: |-
                          The maximum number of times an individual inference request to a model server should be retried.
                          If the maximum number of retries is exceeded without a successgful response, the request will be considered failed.
                        format: int32
                        type: integer
                      retryInterval:
                        default: 100ms
                        description: RetryInterval is the interval between retries.
                        type: string
                    type: object
                  timeout:
                    description: |-
                      The request timeout for the inference request.
                      By default, there is no timeout.
                    type: string
                type: object
              workloadPort:
                description: WorkloadPort defines the port and protocol configuration
                  for the model server.
                properties:
                  port:
                    description: The port of the model server. The number must be
                      between 1 and 65535.
                    format: int32
                    maximum: 65535
                    minimum: 1
                    type: integer
                  protocol:
                    default: http
                    description: The protocol of the model server. Supported values
                      are "http" and "https".
                    enum:
                    - http
                    - https
                    type: string
                required:
                - port
                type: object
              workloadSelector:
                description: |-
                  WorkloadSelector is used to match the model servring instances.
                  Currently they must be pods within the same namespace as modelServer object.
                properties:
                  matchLabels:
                    additionalProperties:
                      type: string
                    description: |-
                      The base labels to match the model serving instances.
                      All serving instances must match these labels.
                    type: object
                  pdGroup:
                    description: |-
                      PDGroup is used to further match different roles of the model serving instances,
                      mainly used in case like PD disaggregation.
                    properties:
                      decodeLabels:
                        additionalProperties:
                          type: string
                        description: The labels to match the model serving instances
                          for decode.
                        type: object
                      groupKey:
                        description: |-
                          GroupKey is the key to distinguish different PD groups.
                          Only PD instances with the same group key and value could be paired.
                        type: string
                      prefillLabels:
                        additionalProperties:
                          type: string
                        description: The labels to match the model serving instances
                          for prefill.
                        type: object
                    required:
                    - decodeLabels
                    - groupKey
                    - prefillLabels
                    type: object
                type: object
            required:
            - inferenceEngine
            - workloadSelector
            type: object
          status:
            description: ModelServerStatus defines the observed state of ModelServer.
            type: object
        type: object
    served: true
    storage: true
    subresources:
      status: {}
