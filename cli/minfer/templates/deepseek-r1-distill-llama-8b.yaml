# Description: Template for DeepSeek R1 Distill Llama 8B model deployment with vLLM backend
apiVersion: registry.matrixinfer.ai/v1alpha1
kind: Model
metadata:
  annotations:
    api.kubernetes.io/name: {{ .Values.annotationName | default "example" | quote }}
  name: {{ .Values.name | default "deepseek-r1-distill-llama-8b" | quote }}
  {{- if .Values.namespace }}
  namespace: {{ .Values.namespace | quote }}
  {{- end }}
spec:
  name: {{ .Values.modelName | default .Values.name | default "deepseek-r1-distill-llama-8b" | quote }}
  owner: {{ .Values.owner | default "example" | quote }}
  autoscalingPolicy:
    metrics:
      - metricName: {{ .Values.metricName | default "matrixinfer:num_requests_waiting" | quote }}
        targetValue: {{ .Values.targetValue | default 10 }}
  backends:
    - name: {{ .Values.backendName | default "deepseek-r1-distill-llama-8b-vllm" | quote }}
      type: {{ .Values.backendType | default "vLLM" | quote }}
      modelURI: {{ .Values.modelURI | default "s3://model-bucket/deepseek-r1-distill-llama-8b" | quote }}
      cacheURI: {{ .Values.cacheURI | default "hostpath://tmp/test" | quote }}
      minReplicas: {{ .Values.minReplicas | default 1 }}
      maxReplicas: {{ .Values.maxReplicas | default 3 }}
      scalingCost: {{ .Values.scalingCost | default 1 }}
      scaleToZeroGracePeriod: {{ .Values.scaleToZeroGracePeriod | default "60s" | quote }}
      workers:
        - type: {{ .Values.workerType | default "server" | quote }}
          image: {{ .Values.workerImage | default "vllm/vllm-openai:v0.7.1" | quote }}
          replicas: {{ .Values.workerReplicas | default 0 }}
          pods: {{ .Values.workerPods | default 0 }}
          config:
            maxModelLen: {{ .Values.maxModelLen | default 12288 }}
          resources:
            limits:
              nvidia.com/gpu: {{ .Values.gpuLimit | default "1" | quote }}
            requests:
              nvidia.com/gpu: {{ .Values.gpuRequest | default "1" | quote }}
      {{- if .Values.loraAdapters }}
      loraAdapters:
      {{- range .Values.loraAdapters }}
        - name: {{ .name | quote }}
          artifactURL: {{ .artifactURL | quote }}
      {{- end }}
      {{- else }}
      loraAdapters:
        - name: {{ .Values.loraAdapterName | default "lora-sql" | quote }}
          artifactURL: {{ .Values.loraAdapterURL | default "s3://aios_models/deepseek-ai/DeepSeek-V3-W8A8/vllm-ascend-lora" | quote }}
      {{- end }}