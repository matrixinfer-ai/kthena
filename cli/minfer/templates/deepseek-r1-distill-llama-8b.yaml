# Description: Template for DeepSeek R1 Distill Llama 8B model deployment with vLLM backend
apiVersion: registry.matrixinfer.ai/v1alpha1
kind: Model
metadata:
  annotations:
    api.kubernetes.io/name: "{{ .Values.annotationName | default "example" }}"
  name: "{{ .Values.name | default "deepseek-r1-distill-llama-8b" }}"
{{- if .Values.namespace }}
  namespace: "{{ .Values.namespace }}"
{{- end }}
spec:
  name: "{{ .Values.modelName | default .Values.name | default "deepseek-r1-distill-llama-8b" }}"
  owner: "{{ .Values.owner | default "example" }}"
  autoscalingPolicy:
    metrics:
      - metricName: "{{ .Values.metricName | default "matrixinfer:num_requests_waiting" }}"
        targetValue: {{ .Values.targetValue | default 10 }}
  backends:
    - name: "{{ .Values.backendName | default "deepseek-r1-distill-llama-8b-vllm" }}"
      type: "{{ .Values.backendType | default "vLLM" }}"
      modelURI: "{{ .Values.modelURI | default "s3://model-bucket/deepseek-r1-distill-llama-8b" }}"
      cacheURI: "{{ .Values.cacheURI | default "hostpath://tmp/test" }}"
      minReplicas: {{ .Values.minReplicas | default 1 }}
      maxReplicas: {{ .Values.maxReplicas | default 3 }}
      scalingCost: {{ .Values.scalingCost | default 1 }}
      scaleToZeroGracePeriod: {{ .Values.scaleToZeroGracePeriod | default "60s" }}
      workers:
        - type: "{{ .Values.workerType | default "server" }}"
          image: "{{ .Values.workerImage | default "vllm/vllm-openai:v0.7.1" }}"
          replicas: {{ .Values.workerReplicas | default 0 }}
          pods: {{ .Values.workerPods | default 0 }}
          config:
            maxModelLen: {{ .Values.maxModelLen | default 12288 }}
          resources:
            limits:
              nvidia.com/gpu: "{{ .Values.gpuLimit | default "1" }}"
            requests:
              nvidia.com/gpu: "{{ .Values.gpuRequest | default "1" }}"
{{- if .Values.loraAdapters }}
      loraAdapters:
{{- range .Values.loraAdapters }}
        - name: {{ .name }}
          artifactURL: {{ .artifactURL }}
{{- end }}
{{- else }}
      loraAdapters:
        - name: "{{ .Values.loraAdapterName | default "lora-sql" }}"
          artifactURL: "{{ .Values.loraAdapterURL | default "s3://aios_models/deepseek-ai/DeepSeek-V3-W8A8/vllm-ascend-lora" }}"
{{- end }}