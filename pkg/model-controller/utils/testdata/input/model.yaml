apiVersion: registry.matrixinfer.ai/v1alpha1
kind: Model
metadata:
  name: test-model
  namespace: default
  uid: randomUID
spec:
  backends:
    - name: backend1
      type: vLLM
      modelURI: s3://aios_models/deepseek-ai/DeepSeek-V3-W8A8/vllm-ascend
      cacheURI: hostpath:///tmp/test
      maxReplicas: 0
      minReplicas: 1
      env:
        - name: ENDPOINT
          value: https://obs.test.com
        - name: RUNTIME_PORT
          value: "8900"
      envFrom:
        - secretRef:
            name: test-secret
      workers:
        - image: vllm-server:latest
          pods: 1
          config:
            block-size: 128
            gpu-memory-utilization: 0.9
            max-model-len: 32768
            tensor-parallel-size: 2
            trust-remote-code: ""
          resources:
            requests:
              cpu: 100m
              huawei.com/ascend-1980: "1"
              memory: 1Gi
          type: server
