apiVersion: workload.matrixinfer.ai/v1alpha1
kind: modelinfer
metadata: ${MODEL_INFER_TEMPLATE_METADATA}
spec:
  recoveryPolicy: InferGroupRecreate
  rolloutStrategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: InferGroupRollingUpdate
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: DoNotSchedule
      labelSelector:
        matchLabels:
          modelinfer/name: ${MODEL_NAME}
  replicas: ${BACKEND_REPLICAS}
  template:
    restartGracePeriodSeconds: 60
    networkTopology:
      mode: hard
      highestTierAllowed: 2
    gangScheduling:
      minMember: 4
    roles:
      - name: leader
        replicas: ${SERVER_REPLICAS}
        entryTemplate:
          metadata: ${SERVER_ENTRY_TEMPLATE_METADATA}
          spec:
            initContainers: ${INIT_CONTAINERS}
            terminationGracePeriodSeconds: 300
            volumes: ${VOLUMES}
            containers:
              - name: runtime
                image: ${MODEL_INFER_RUNTIME_IMAGE}
                ports:
                  - containerPort: ${MODEL_INFER_RUNTIME_PORT}
                env: ${ENGINE_ENV}
                envFrom: ${MODEL_DOWNLOAD_ENVFROM}
                args:
                  - --port
                  - ${MODEL_INFER_RUNTIME_PORT}
                  - --engine
                  - ${MODEL_INFER_RUNTIME_ENGINE}
                  - --engine-base-url
                  - ${MODEL_INFER_RUNTIME_URL}
                  - --engine-metrics-path
                  - ${MODEL_INFER_RUNTIME_METRICS_PATH}
                  - --pod
                  - ${MODEL_INFER_RUNTIME_POD}
                  - --model
                  - ${MODEL_NAME}
                readinessProbe:
                  httpGet:
                    path: /health
                    port: ${MODEL_INFER_RUNTIME_PORT}
                  initialDelaySeconds: 5
                  periodSeconds: 10
              - name: engine
                image: ${ENGINE_SERVER_IMAGE}
                command: ${ENGINE_SERVER_COMMAND}
                env: ${ENGINE_ENV}
                resources: ${ENGINE_SERVER_RESOURCES}
                volumeMounts: ${VOLUME_MOUNTS}
                readinessProbe:
                  failureThreshold: 3
                  httpGet:
                    path: /health
                    port: 8000
                    scheme: HTTP
                  initialDelaySeconds: 90
                  periodSeconds: 5
                  successThreshold: 1
                  timeoutSeconds: 1
                lifecycle:
                  preStop:
                    exec:
                      command:
                        - /bin/sh
                        - -c
                        - |
                          while true; do
                            RUNNING=$(curl -s http://localhost:8000/metrics | grep 'vllm:num_requests_running' | grep -v '#' | awk '{print $2}')
                            WAITING=$(curl -s http://localhost:8000/metrics | grep 'vllm:num_requests_waiting' | grep -v '#' | awk '{print $2}')
                            if [ "$RUNNING" = "0.0" ] && [ "$WAITING" = "0.0" ]; then
                              echo "Terminating: No active or waiting requests, safe to terminate" >> /proc/1/fd/1
                              exit 0
                            else
                              echo "Terminating: Running: $RUNNING, Waiting: $WAITING" >> /proc/1/fd/1
                              sleep 5
                            fi
                          done
        workerReplicas: ${WORKER_REPLICAS}
        workerTemplate:
          metadata: ${SERVER_WORKER_TEMPLATE_METADATA}
          spec:
            volumes: ${VOLUMES}
            initContainers: ${INIT_CONTAINERS}
            containers:
              - name: ${BACKEND_NAME}-${BACKEND_TYPE}-worker
                image: ${ENGINE_SERVER_IMAGE}
                command:
                  - bash
                  - "-c"
                  - "chmod u+x /vllm-workspace/vllm/examples/online_serving/multi-node-serving.sh && /vllm-workspace/vllm/examples/online_serving/multi-node-serving.sh worker --ray_address=$(ENTRY_ADDRESS)"
                env: ${WORKER_ENV}
                resources: ${ENGINE_SERVER_RESOURCES}
                volumeMounts: ${VOLUME_MOUNTS}
