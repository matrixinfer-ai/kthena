apiVersion: networking.matrixinfer.ai/v1alpha1
kind: ModelServer
metadata:
  name: test-model-0-vllm-server
  namespace: default
  labels:
    registry.matrixinfer.ai/backend-name: backend1
    registry.matrixinfer.ai/managed-by: registry.matrixinfer.ai
    registry.matrixinfer.ai/model-name: test-model
    registry.matrixinfer.ai/model-uid: randomUID
    registry.matrixinfer.ai/revision: 6bb65f6764
  ownerReferences:
    - apiVersion: registry.matrixinfer.ai/v1alpha1
      blockOwnerDeletion: true
      controller: true
      kind: Model
      name: test-model
      uid: randomUID
spec:
  model: "deepseek-v3"
  inferenceEngine: "vLLM"
  workloadSelector:
    matchLabels:
      registry.matrixinfer.ai/backend-name: backend1
      registry.matrixinfer.ai/managed-by: registry.matrixinfer.ai
      registry.matrixinfer.ai/model-name: test-model
      registry.matrixinfer.ai/model-uid: randomUID
      registry.matrixinfer.ai/revision: 6bb65f6764
  workloadPort:
    port: 8000
  trafficPolicy:
    retry:
      attempts: 5
      retryInterval: 0s